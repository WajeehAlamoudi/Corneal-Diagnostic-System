{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:10:38.099873Z",
     "start_time": "2025-12-06T13:10:35.604180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "feature_extractor = nn.Sequential(*list(backbone.children())[:-1])\n",
    "feature_extractor = feature_extractor.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "dcde4263e8fbbef8",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:10:40.432451Z",
     "start_time": "2025-12-06T13:10:38.100875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from classes import VisionModule\n",
    "from config import configuration\n",
    "\n",
    "vision_model_obj = VisionModule( feature_extraction_model=feature_extractor, configuration=configuration )"
   ],
   "id": "4ad37c86f6e22e5f",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:10:41.719948Z",
     "start_time": "2025-12-06T13:10:40.432812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from classes import TextModule\n",
    "\n",
    "text_model_obj = TextModule()"
   ],
   "id": "24ec2fe2097b2143",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:18:24.831158Z",
     "start_time": "2025-12-06T13:18:24.821283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "def test_architecture_pipeline(img_path):\n",
    "\n",
    "    print(\"\\n==================== TEST PIPELINE ====================\")\n",
    "\n",
    "    # 1. Preprocess â†’ get crops folder\n",
    "    crops_path = vision_model_obj.run_image_preprocessing(img_path)\n",
    "\n",
    "    if crops_path is None or not os.path.exists(crops_path):\n",
    "        print(\"[ERROR] run_image_preprocessing() did not return a valid folder.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    #  Prepare save dirs (TEMP STORAGE for test)\n",
    "    base = os.path.dirname(os.path.dirname(img_path))\n",
    "\n",
    "    deep_dir = os.path.join(base, \"test_deep_features\")\n",
    "    hand_dir = os.path.join(base, \"test_hand_features\")\n",
    "    trans_dir = os.path.join(base, \"test_transformer_features\")\n",
    "\n",
    "    os.makedirs(deep_dir, exist_ok=True)\n",
    "    os.makedirs(hand_dir, exist_ok=True)\n",
    "    os.makedirs(trans_dir, exist_ok=True)\n",
    "\n",
    "    img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Extract features for each quadrant\n",
    "    quadrant_list = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "    quadrant_vectors = []\n",
    "    handcrafted_all_quadrants = {}\n",
    "\n",
    "    for q in quadrant_list:\n",
    "\n",
    "        crop_path = os.path.join(crops_path, f\"{img_id}_{q}.png\")\n",
    "\n",
    "        if not os.path.exists(crop_path):\n",
    "            print(f\"[WARN] Missing crop: {crop_path}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # LOAD CROP\n",
    "        crop = cv2.imread(crop_path)\n",
    "        crop = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "        # DEEP FEATURES\n",
    "\n",
    "        cnn_ready = vision_model_obj.preprocess_for_cnn(crop)\n",
    "        deep_vec = vision_model_obj.extract_deep_features(\n",
    "            tensor=cnn_ready,\n",
    "            save_dir=deep_dir,\n",
    "            img_name=img_id,\n",
    "            quadrant=q\n",
    "        )\n",
    "\n",
    "\n",
    "        # HANDCRAFT FEATURES\n",
    "\n",
    "        hand_vec = vision_model_obj.handcrafted_features(\n",
    "            cropped_img_pth=crop_path,\n",
    "            save_dir=hand_dir,\n",
    "            img_name=img_id,\n",
    "            quadrant=q\n",
    "        )\n",
    "        handcrafted_all_quadrants[q] = hand_vec\n",
    "\n",
    "        hand_vec = np.array(list(hand_vec.values()), dtype=np.float32)\n",
    "\n",
    "        # TRANSFORMER FEATURES\n",
    "        trans_vec = text_model_obj.extract_transformer_features(\n",
    "            img_path=crop_path,\n",
    "            save_dir=trans_dir,\n",
    "            img_name=img_id,\n",
    "            quadrant=q\n",
    "        )\n",
    "\n",
    "\n",
    "        # CONCATENATE 3 MODALITIES FOR THIS QUADRANT\n",
    "\n",
    "        fused_vec = np.concatenate([deep_vec, hand_vec, trans_vec], axis=0)\n",
    "        quadrant_vectors.append(fused_vec)\n",
    "\n",
    "    if len(quadrant_vectors) == 0:\n",
    "        print(\"[ERROR] No valid quadrant vectors extracted.\")\n",
    "        return None\n",
    "\n",
    "    #  FINAL IMAGE FEATURE = AVERAGE OF QUADRANTS\n",
    "    final_feature_vec = np.mean(quadrant_vectors, axis=0)\n",
    "\n",
    "\n",
    "    # LOAD TRAINED XGBOOST MODEL\n",
    "    model_path = r\"saved_models/kc_classifier.pkl\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"[ERROR] XGBoost model file not found:\", model_path)\n",
    "        return None\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "    pred_prob = model.predict_proba(final_feature_vec.reshape(1, -1))[0]\n",
    "    pred_class = model.predict(final_feature_vec.reshape(1, -1))[0]\n",
    "\n",
    "    label_map = {0: \"normal\", 1: \"Keratoconus\"}\n",
    "    pred_label = label_map[int(pred_class)]\n",
    "\n",
    "    print(\"\\n==================== RESULT ====================\")\n",
    "    print(f\"Prediction: {pred_label}\")\n",
    "    print(f\"Probability: normal={pred_prob[0]:.4f}, KC={pred_prob[1]:.4f}\")\n",
    "    print(\"=================================================\\n\")\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 7. OUTPUTS FOR LLM REPORT\n",
    "    # ---------------------------------------------------\n",
    "    final_prediction = {\n",
    "        \"image_id\": img_id,\n",
    "        \"predicted_label\": pred_label,\n",
    "        \"probabilities\": {\n",
    "            \"normal\": float(pred_prob[0]),\n",
    "            \"keratoconus\": float(pred_prob[1])\n",
    "        },\n",
    "        \"handcrafted_summary\": handcrafted_all_quadrants\n",
    "    }\n",
    "    \n",
    "    plain_prompt = f\"\"\"\n",
    "    You are a clinical ophthalmology assistant specialized in interpreting corneal topography,\n",
    "    keratoconus patterns, and handcrafted corneal image features.\n",
    "    \n",
    "    Your task is to provide a structured, clinically accurate summary.\n",
    "    \n",
    "    ==============================\n",
    "    INPUT DATA\n",
    "    ==============================\n",
    "    Image ID: {img_id}\n",
    "    \n",
    "    Model Output:\n",
    "    - Predicted Class: {pred_label}\n",
    "    - Probability (Normal): {final_prediction['probabilities']['normal']:.4f}\n",
    "    - Probability (Keratoconus): {final_prediction['probabilities']['keratoconus']:.4f}\n",
    "    \n",
    "    Handcrafted Feature Summary (All Quadrants):\n",
    "    {handcrafted_all_quadrants}\n",
    "    \n",
    "    ==============================\n",
    "    YOUR TASK\n",
    "    ==============================\n",
    "    \n",
    "    Using the data above, produce a concise but clinically meaningful interpretation that includes:\n",
    "    \n",
    "    1. **Overall Diagnostic Impression**\n",
    "       - What the predicted class suggests clinically.\n",
    "       - Whether the probability supports a strong or weak suspicion.\n",
    "    \n",
    "    2. **Quadrant-by-Quadrant Interpretation**\n",
    "       For each quadrant explicitly mentioned in the handcrafted summary:\n",
    "       - Describe what the color intensity, texture, dominant color, or extracted features may indicate.\n",
    "       - Whether the quadrant shows signs consistent with:\n",
    "         * normal corneal structure\n",
    "         * mild irregularity\n",
    "         * early keratoconus changes\n",
    "         * focal thinning or localized steepening\n",
    "         * abnormal reflection patterns\n",
    "       - Explain what these abnormalities typically mean clinically.\n",
    "    \n",
    "    3. **Handcrafted Feature Interpretation**\n",
    "       - Explain what the extracted handcrafted cues (e.g., color dominance, pixel distribution,\n",
    "         contrast, asymmetry across quadrants) could imply about corneal shape or regularity.\n",
    "       - Highlight any quadrant asymmetry (superior vs inferior, temporal vs nasal).\n",
    "    \n",
    "    4. **Final Clinical Summary**\n",
    "       - Summarize the findings in professional medical language.\n",
    "       - Clearly state whether the results lean toward a normal cornea, subclinical keratoconus,\n",
    "         or keratoconus.\n",
    "       - If appropriate, suggest what further clinical tests would normally be recommended\n",
    "         (e.g., tomography, pachymetry, topographic maps).\n",
    "    \n",
    "    ==============================\n",
    "    RULES\n",
    "    ==============================\n",
    "    - Do NOT hallucinate missing measurements (e.g., K1, K2, pachymetry) if not provided.\n",
    "    - Base your interpretation strictly on the handcrafted features and quadrant descriptors.\n",
    "    - Be concise but clinically meaningful.\n",
    "    - Do not output code; only the clinical interpretation.\n",
    "    \n",
    "    Now provide the clinical interpretation:\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    return final_prediction, plain_prompt\n",
    "    "
   ],
   "id": "d218f0a077b249bc",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:18:27.580087Z",
     "start_time": "2025-12-06T13:18:27.573946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown, display\n",
    "import ipywidgets as widgets\n",
    "from classes import GEMINIAGENT\n",
    "\n",
    "def run_with_chat(img_path):\n",
    "    # 1. Run your vision + XGBoost pipeline\n",
    "    final_prediction, prompt_text = test_architecture_pipeline(img_path)\n",
    "\n",
    "    # 2. Create Gemini agent\n",
    "    agent = GEMINIAGENT(\n",
    "        #api_key=\"AIzaSyC8afVIleDMMOtCJAxlyHLgKevYySxorwU\",\n",
    "        # <put it here on purpose>\n",
    "        api_key=\"YOUR_KEY_HERE\",\n",
    "        system_message=\"\"\"\n",
    "        You are a medical assistant and OCULUS - PENTACAM 4 Maps analysis.\n",
    "        \"\"\",\n",
    "        model=\"gemini-2.5-flash\"\n",
    "    )\n",
    "\n",
    "    # 3. Auto clinical report\n",
    "    report = agent.ask(prompt_text)\n",
    "    display(Markdown(\"## Clinical Report\\n\\n\" + report))\n",
    "\n",
    "    # -------- CHAT MODE --------\n",
    "    print(\"\\n===== CHAT MODE =====\")\n",
    "    \n",
    "    # Create output area for chat history\n",
    "    chat_output = widgets.Output()\n",
    "    \n",
    "    input_box = widgets.Text(\n",
    "        placeholder=\"Type your question...\",\n",
    "        description=\"You:\",\n",
    "        layout=widgets.Layout(width=\"500px\")\n",
    "    )\n",
    "\n",
    "    send_button = widgets.Button(\n",
    "        description=\"Send\",\n",
    "        button_style=\"success\"\n",
    "    )\n",
    "    \n",
    "    # Container for input controls\n",
    "    input_container = widgets.HBox([input_box, send_button])\n",
    "\n",
    "    def send_message(_):\n",
    "        user_input = input_box.value.strip()\n",
    "        if not user_input:\n",
    "            return\n",
    "\n",
    "        input_box.value = \"\"  # Clear box\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            with chat_output:\n",
    "                print(\"Chat ended.\")\n",
    "            return\n",
    "\n",
    "        # Display user message\n",
    "        with chat_output:\n",
    "            display(Markdown(f\"**You:** {user_input}\"))\n",
    "        \n",
    "        # Get and display assistant reply\n",
    "        try:\n",
    "            reply = agent.ask(user_input)\n",
    "            with chat_output:\n",
    "                display(Markdown(f\"**Assistant:** {reply}\\n\\n---\\n\"))\n",
    "        except Exception as e:\n",
    "            with chat_output:\n",
    "                display(Markdown(f\"**Error:** {str(e)}\\n\\n---\\n\"))\n",
    "\n",
    "    # Allow Enter key to send message\n",
    "    def handle_submit(sender):\n",
    "        send_message(None)\n",
    "    \n",
    "    input_box.on_submit(handle_submit)\n",
    "    send_button.on_click(send_message)\n",
    "    \n",
    "    # Display the interface\n",
    "    display(input_container)\n",
    "    display(chat_output)"
   ],
   "id": "83ee79112e03d6d",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:18:50.578934Z",
     "start_time": "2025-12-06T13:18:29.917449Z"
    }
   },
   "cell_type": "code",
   "source": "run_with_chat(\"dataset/test/images/4.jpg\")",
   "id": "8e6bfdaeedbb6e88",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T13:11:19.924083Z",
     "start_time": "2025-12-06T13:11:19.924083Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5bc449dbcff0def",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
